# NOTE: Blank strings ("") act as placeholders when information is not yet known.
# Columns: name, link, subjects, signals, neurorecording_system, minutes,
#          stimulus_type, stimuli_description, tasks, competing_talker_sex,
#          talker_sex, participant_population, authors, publication, extras
- name: EEG Music-listening Experiment Dataset (AUTh)
  link: https://github.com/AdamosDA/Music-EEG
  paper: https://doi.org/10.1088/1741-2552/abffe6
  subjects: 20
  signals: EEG
  neurorecording_system: "Emotiv EPOC+ (mobile EEG headset)"
  minutes: 40
  stimulus_type: music
  stimuli_description: "Personalized playlists: 30 song excerpts per participant (80s each) rated as 'OK', 'like', or 'favorite'; playlist compiled in consultation with experimenter."
  tasks: [music, enjoyment_rating, personalized_playlist]
  competing_talker_sex: ""
  talker_sex: "varied"
  participant_population: "university students, young adults; 10 female, 6 without musical training"
  authors: "S. Bakas, D. A. Adamos, N. Laskaris"
  publication: "Bakas, S., Adamos, D. A., & Laskaris, N. (2021). On the estimate of Music Appraisal from surface EEG: a dynamic-network approach based on Cross-Sensor PAC measurements. Journal of Neural Engineering, 18(4), 046018. https://doi.org/10.1088/1741-2552/abffe6"
  extras: "EEG resting-state data included (70s); song ratings collected before listening; 10 songs per rating category; preprocessed data (filtered 1–45 Hz, wavelet-ICA); 128 Hz sampling; sensor info included"

- name: MUSIN-G (Music Listening–Genre EEG Dataset)
  link: https://openneuro.org/datasets/ds003774/versions/1.0.2
  paper: ""
  subjects: 20
  signals: EEG
  neurorecording_system: "unspecified (OpenNeuro)"
  minutes: 12
  stimulus_type: music
  stimuli_description: "12 songs per participant spanning genres from Indian Classical to Goth Rock; each session is a different song"
  tasks: [music, enjoyment_rating, familiarity_rating]
  competing_talker_sex: ""
  talker_sex: "varied"
  participant_population: "Indian adults"
  authors: "K. P. Miyapuram, P. Pandey, N. Ahmad, B. R. Shiraguppi, E. Sharma, P. Lawhatre, D. Sonawane, D. Lomas"
  publication: ""
  extras: "Each trial: eyes closed for listening, then eyes open for rating familiarity and enjoyment (1=most familiar/enjoyable, 5=least); event timings in segmented data must be ignored; 1.0.2 is the correct, non-deprecated version"

- name: Narratives fMRI
  link: https://openneuro.org/datasets/ds002345
  paper: https://www.nature.com/articles/s41597-021-01033-3
  subjects: 345
  signals: fMRI
  neurorecording_system: "3T MRI (various Siemens and GE models)"
  minutes: 300
  stimulus_type: spoken_stories
  stimuli_description: "Naturalistic spoken stories (27 unique stories; fiction and nonfiction; total ~4.6 hours; ~43,000 words; professionally narrated by male and female speakers)"
  tasks: [story_listening, language_comprehension]
  competing_talker_sex: ""
  talker_sex: "male and female"
  participant_population: "healthy adults, ages 18–55"
  authors: "S. A. Nastase, Y.-F. Liu, H. Hillman, A. Zadbood, L. Hasenfratz, N. Keshavarzian, J. Chen, C. J. Honey, Y. Yeshurun, M. Regev, M. Nguyen, C. H. C. Chang, C. Baldassano, O. Lositsky, E. Simony, M. A. Chow, Y. C. Leong, P. P. Brooks, E. Micciche, G. Choe, A. Goldstein, T. Vanderwal, Y. O. Halchenko, K. A. Norman, U. Hasson"
  publication: "Nastase et al., Scientific Data, 2021"
  extras: "891 functional scans; BIDS-compliant; includes anatomical scans, time-stamped transcripts, rich metadata, and preprocessed data; widely used benchmark for naturalistic neuroimaging and language models."

- name: ASA (Auditory Spatial Attention Dataset)
  link: https://zenodo.org/records/11541114
  paper: https://www.isca-archive.org/interspeech_2024/lin24f_interspeech.pdf
  subjects: 20
  signals: EEG
  neurorecording_system: "EEG 64-channel Easycap"
  minutes: 24
  stimulus_type: audio
  stimuli_description: "Mandarin stories; two speakers per trial from 10 different spatial locations (±90°, ±60°, ±45°, ±30°, ±5°); HRTF-filtered for headphones"
  tasks: [attention_decoding, spatial_localization]
  competing_talker_sex: "male-female"
  talker_sex: "male and female"
  participant_population: "normal hearing"
  authors: "Z. Lin, T. He, S. Cai, H. Li"
  publication: "Lin et al., Interspeech 2024"
  extras: "20 trials × 1–1.5 min; baseline code (CA-CNN) and evaluation scripts provided; first ASAD dataset with multiple spatial locations"

- name: AV-GC-AAD
  link: https://zenodo.org/records/11058711
  paper: https://iopscience.iop.org/article/10.1088/1741-2552/ad2214/meta
  subjects: 13
  signals: EEG
  neurorecording_system: "EEG 64-channel BioSemi (+4 EOG)"
  minutes: 80
  stimulus_type: audiovisual
  stimuli_description: "Dutch science-outreach podcasts with various audio-visual and gaze conditions; spatial attention switch after 5 min per trial"
  tasks: [attention_decoding, gaze_control]
  competing_talker_sex: "male-male"
  talker_sex: "male"
  participant_population: "young, normal hearing"
  authors: "I. Rotaru, S. Geirnaert, N. Heintz, I. Van de Ryck, A. Bertrand, T. Francart"
  publication: "Rotaru et al., J. Neural Eng., 2024"
  extras: "2 blocks × 4 conditions × 10 min; HRTF-filtered; 4 visual conditions (moving video/crosshair, static video, no visuals); EOG for gaze; per trial one attention switch; anechoic room"

- name: Auditory Brainstem AAD (Reichenbach)
  link: https://zenodo.org/records/7778289
  paper: https://www.sciencedirect.com/science/article/pii/S1053811919305208
  subjects: 18
  signals: EEG
  neurorecording_system: "EEG 64-channel actiCAP"
  minutes: 20
  stimulus_type: audio
  stimuli_description: "English audiobooks; dichotic competing speakers"
  tasks: [attention_decoding, brainstem_response]
  competing_talker_sex: "male-female"
  talker_sex: "male and female"
  participant_population: "young, normal hearing"
  authors: "O. Etard, M. Kegler, C. Braiman, A.E. Forte, T. Reichenbach"
  publication: "Etard et al., NeuroImage, 2019"
  extras: "2 trials × 4 parts × 2.5 min; 90/-90° speaker separation; HDF5 format; also used for delta/theta tracking"

- name: NJU Auditory Attention Decoding
  link: https://ieee-dataport.org/documents/nju-auditory-attention-decoding-dataset
  paper: https://ieeexplore.ieee.org/abstract/document/10096819
  subjects: 21
  signals: EEG
  neurorecording_system: "EEG 32-channel EMOTIV Epoc Flex Saline"
  minutes: 64
  stimulus_type: audio
  stimuli_description: "Chinese news programs; two-talker competing speaker paradigm; random pairs of spatial directions per trial"
  tasks: [attention_decoding, directional_decoding, multi_speaker]
  competing_talker_sex: "male-female"
  talker_sex: "male and female"
  participant_population: "normal hearing"
  authors: "Y. Zhang, H. Ruan, Z. Yuan, H. Du, X. Gao, J. Lu"
  publication: "Zhang et al., ICASSP, 2023"
  extras: "15 random competing speaker directions (±135°, ±120°, ±90°, ±60°, ±45°, ±30°, ±15°, 0°); loudspeaker array; 32 trials × 2 min"

- name: MEG Natural Speech (Simon)
  link: https://drum.lib.umd.edu/items/6ce1b090-3446-46d8-9582-f689afcd23de
  paper: https://www.sciencedirect.com/science/article/pii/S096098221831409X
  subjects: 26
  signals: MEG
  neurorecording_system: "MEG 157-channel"
  minutes: 16
  stimulus_type: audio
  stimuli_description: "English audiobooks (mix of male and female talkers); analyzed acoustic, phonetic, and lexical neural responses"
  tasks: [speech_perception, lexical_processing, selective_attention]
  competing_talker_sex: "male-female"
  talker_sex: "male and female"
  participant_population: "normal-hearing"
  authors: "C. Brodbeck, L. E. Hong, J. Z. Simon"
  publication: "Brodbeck et al., Current Biology, 2018"
  extras: "Cocktail-party and single-speaker paradigms; word and phoneme onsets provided; 4 trials x 4 repetitions x 1 min"

- name: MEG State-Space AAD
  link: https://drum.lib.umd.edu/items/d935265d-895c-4fc7-aec2-36dc7682d87d
  paper: https://www.sciencedirect.com/science/article/abs/pii/S1053811915008708
  subjects: 7
  signals: MEG
  neurorecording_system: "MEG 157-channel"
  minutes: 6
  stimulus_type: audio
  stimuli_description: "English fictional stories with two competing speakers (male-female), dichotic presentation at ±90°; instructed attention switches once per trial"
  tasks: [attention_decoding, multi_speaker, attention_switch]
  competing_talker_sex: "male-female"
  talker_sex: "male-female"
  participant_population: "young, normal hearing"
  authors: "S. Akram, A. Presacco, J. Z. Simon, S. A. Shamma, B. Babadi"
  publication: "Akram et al., NeuroImage, 2016"
  extras: "Instructed attention switch paradigm; state-space decoding; 2 conditions × 3 repetitions × 1 min"

- name: Neural Tracking to Go (Straetmans)
  link: https://openneuro.org/datasets/ds003801/versions/1.0.0
  paper: https://iopscience.iop.org/article/10.1088/1741-2552/ac42b5
  subjects: 20
  signals: EEG
  neurorecording_system: "EEG 24-channel EasyCap/SMARTING"
  minutes: 30
  stimulus_type: audio
  stimuli_description: "German audiobooks with natural salient events, two competing speakers (male-male), HRTF-filtered at ±45°, in public cafeteria without other people; 3 trials sitting, 3 trials walking, salient environmental sounds"
  tasks: [attention_decoding, multi_speaker, saliency_detection, mobile_recording]
  competing_talker_sex: "male-male"
  talker_sex: "male-male"
  participant_population: "young, normal hearing"
  authors: "L. Straetmans, B. Holtze, S. Debener, M. Jaeger, B. Mirkovic"
  publication: "Straetmans et al., J. Neural Eng. 2021"
  extras: "Mobile EEG; trials in both walking and sitting; salient environmental sounds added as distractors; BIDS format (OpenNeuro)"

- name: OpenMIIR
  link: https://github.com/sstober/openmiir
  paper: https://ismir2015.ismir.net/proceedings/ISMIR2015_p763_stober.pdf
  subjects: 10
  signals: EEG
  neurorecording_system: "EEG 64-channel Brain Products ActiCAP"
  minutes: "Varies (~30-40 min per subject)"
  stimulus_type: music
  stimuli_description: "12 well-known music fragments (7–16s), each subject listens to and imagines the melodies"
  tasks: [music_perception, music_imagery, classification]
  competing_talker_sex: ""
  talker_sex: "instrumental + vocals"
  participant_population: "young adults"
  authors: "S. Stober, A. Sternin, A. M. Owen, J. A. Grahn"
  publication: "Stober et al., ISMIR 2015"
  extras: "Perception and imagery; data in FIF format, public domain"

- name: EEG Speech-in-Noise (Etard & Reichenbach)
  link: https://zenodo.org/records/7778289
  paper: https://www.jneurosci.org/content/39/29/5750
  subjects: 12
  signals: EEG
  neurorecording_system: "EEG 64-channel actiCAP"
  minutes: 40
  stimulus_type: audio
  stimuli_description: "English audiobooks in four levels of babble noise; also includes Dutch listening conditions (very low comprehension)."
  tasks: [speech_in_noise, neural_speech_tracking, clarity_decoding, comprehension_decoding]
  competing_talker_sex: ""
  talker_sex: "male and female"
  participant_population: "young, normal-hearing"
  authors: "O. Etard, T. Reichenbach"
  publication: "Etard et al., Journal of Neuroscience, 2019"
  extras: "EEG in English (clean + 3 noise levels) and Dutch (very low comprehension); word- and sentence-level timing files; HDF5 format; CC0 license; see also associated attention decoding publication"

- name: MOUS
  link: https://data.donders.ru.nl/collections/di/dccn/DSC_3011020.09_236?0
  paper: https://www.sciencedirect.com/science/article/pii/S096098221831409X
  subjects: 204
  signals: MEG
  neurorecording_system: "MEG 275-channel (CTF)"
  minutes: 8.4
  stimulus_type: audio
  stimuli_description: "Dutch sentences (120 sentences × 2.8–6 s); listening task; scrambled and normal sentences"
  tasks: [oscillatory_entrainment, language_comprehension, sentence_processing, lateralisation, resting_state]
  competing_talker_sex: ""
  talker_sex: "female"
  participant_population: "young, healthy"
  authors: "N. H. L. Lam, A. Hultén, P. Hagoort, J.-M. Schoffelen"
  publication: "Lam et al., Language, Cognition and Neuroscience, 2018"
  extras: "MEG/fMRI/structural, also includes reading, resting-state, fMRI available for all"

- name: EEG Alice in Wonderland (Brennan)
  link: https://deepblue.lib.umich.edu/data/concern/data_sets/bg257f92t
  paper: https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0207741
  subjects: 49
  signals: EEG
  neurorecording_system: "EEG 61-channel actiCAP (Brain Products actiCHamp)"
  minutes: 12.4
  stimulus_type: audio
  stimuli_description: "English audiobook ('Alice in Wonderland' chapter 1); passive listening; includes stimulus wav files and aligned word-by-word linguistic annotations"
  tasks: [linguistic_prediction, surprisal_tracking, continuous_speech_comprehension]
  competing_talker_sex: ""
  talker_sex: "female"
  participant_population: "young"
  authors: "J. R. Brennan, J. T. Hale"
  publication: "Brennan et al., PLoS ONE, 2019"
  extras: "Comprehension scores, word-by-word surprisal annotations"

- name: SparrKULee (KU Leuven)
  link: https://rdr.kuleuven.be/dataset.xhtml?persistentId=doi:10.48804/K3VSND
  paper: ""
  subjects: 85
  signals: EEG
  neurorecording_system: "EEG 64-channel BioSemi"
  minutes: 130-150
  stimulus_type: audio
  stimuli_description: "Flemish audiobooks and podcasts; 8–10 trials of ~15 min; natural speech listening"
  tasks: [speech_decoding, speech_encoding, match_mismatch, machine_learning]
  competing_talker_sex: ""
  talker_sex: "male and female"
  participant_population: "young, normal-hearing"
  authors: "L. Bollens, B. Accou, H. Van hamme, T. Francart"
  publication: "Bollens et al., KU Leuven RDR, 2023"
  extras: "Code for preprocessing and validation. "

- name: EEG Hearing Aid Speech (Vanheusden)
  link: https://eprints.soton.ac.uk/438737/
  paper: https://www.frontiersin.org/articles/10.3389/fnhum.2020.00109/full
  subjects: 17
  signals: EEG
  neurorecording_system: "EEG 32-channel BioSemi"
  minutes: 25
  stimulus_type: audio
  stimuli_description: "English audiobook; 8 trials of ~3 min each; aided and unaided hearing aid conditions"
  tasks: [cortical_entrainment, hearing_aid, speech_comprehension]
  competing_talker_sex: ""
  talker_sex: "female"
  participant_population: "older, hearing-impaired, hearing aid users"
  authors: "F. J. Vanheusden, et al."
  publication: "Vanheusden et al., Frontiers in Human Neuroscience, 2020"
  extras: "Dataset behavioral results, questionnaires; "

- name: EEG Surprisal (Reichenbach)
  link: https://figshare.com/articles/dataset/EEG_recordings_and_stimuli/9033983/1
  paper: https://www.mitpressjournals.org/doi/10.1162/jocn_a_01467
  subjects: 13
  signals: EEG
  neurorecording_system: "EEG 64-channel actiCAP"
  minutes: 40
  stimulus_type: audio
  stimuli_description: "English short stories; 15 trials of ~2.6 min each; narrative listening"
  tasks: [semantic_decoding, surprisal_tracking, continuous_speech_comprehension]
  competing_talker_sex: ""
  talker_sex: "male"
  participant_population: "young, normal-hearing"
  authors: "H. Weissbart, et al."
  publication: "Weissbart et al., Journal of Cognitive Neuroscience, 2020"
  extras: "Preprocessed EEG for all subjects; word-level stimulus alignment; sample code for temporal response functions; all data in .mat format"

- name: MEG Natural Speech (Simon)
  link: https://drum.lib.umd.edu/items/6ce1b090-3446-46d8-9582-f689afcd23de
  paper: https://doi.org/10.1016/j.cub.2018.10.042
  subjects: 26
  signals: MEG
  neurorecording_system: "MEG 157-channel"
  minutes: 8
  stimulus_type: audio
  stimuli_description: "English audiobooks; 8 trials of 1 minute each; natural narrative speech"
  tasks: [semantic_decoding, surprisal_tracking, continuous_speech_comprehension]
  competing_talker_sex: ""
  talker_sex: "male and female"
  participant_population: "normal-hearing"
  authors: "C. Brodbeck, L. E. Hong, J. Z. Simon"
  publication: "Brodbeck et al., Current Biology, 2018"
  extras: "Includes preprocessed MEG data for all subjects, task: narrative listening, additional documentation files"

- name: EEG Natural Narrative Speech (Lalor)
  link: https://datadryad.org/stash/dataset/doi:10.5061/dryad.070jc
  paper: https://www.cell.com/current-biology/pdf/S0960-9822(18)30132-9.pdf
  subjects: 19
  signals: EEG
  neurorecording_system: "EEG 128-channel BioSemi"
  minutes: 60
  stimulus_type: audio
  stimuli_description: "English fictional stories; includes Cocktail Party, N400, Natural Speech, Reverse Speech, and Speech-in-Noise paradigms"
  tasks: [semantic_decoding, attention_decoding, phoneme_decoding, speech_in_noise]
  competing_talker_sex: ""
  talker_sex: "male"
  participant_population: "young, normal-hearing"
  authors: "M. P. Broderick, et al."
  publication: "Broderick et al., Current Biology, 2018"
  extras: "Paradigms: semantic dissimilarity, cocktail party attention, time-reversed speech, speech in noise, and N400;)"

- name: SEED (SJTU)
  link: https://bcmi.sjtu.edu.cn/~seed/seed.html
  paper: https://ieeexplore.ieee.org/document/7103007  # Zheng & Lu, IEEE TAMD 2015
  subjects: 15
  signals: EEG + Eye-tracking
  neurorecording_system: "EEG 62-channel ESI NeuroScan System; SMI eye-tracking glasses"
  minutes: "180"  # 15 trials x 4min x 3 sessions = 180 min per subject
  stimulus_type: audiovisual
  stimuli_description: "15 Chinese film clips (positive, neutral, negative emotions), ~4 min each, 3 sessions per subject"
  tasks: [emotion_classification, multimodal_decoding]
  competing_talker_sex: ""
  talker_sex: ""
  participant_population: "Chinese adults (7 males, 8 females, mean age 23.3 ± 2.4 yrs)"
  authors: "Wei-Long Zheng, Ruo-Nan Duan, Jia-Yi Zhu, Bao-Liang Lu"
  publication: "Wei-Long Zheng et al. 2015 and Ruo-Nan Duan et al. 2013"
  extras: "Emotions labeled per clip (positive/neutral/negative); Preprocessed and feature-level data"

- name: Open iEEG-fMRI dataset
  link: https://braintreebank.dev/
  paper: "https://openneuro.org/datasets/ds003688/versions/1.0.6"
  subjects: 51 
  signals: iEEG + Respiration + HR + EOG
  neurorecording_system: "iEEG 4865 electrodes"
  minutes: 6.5
  stimulus_type: audiovisual
  stimuli_description: "Short audiovisual film"
  tasks: [naturalistic_viewing]
  competing_talker_sex: ""
  talker_sex: ""
  participant_population: "patients"
  authors: "J. Berezutskaya et al."
  publication: "J. Berezutskaya. scientific data 2022"
  extras: "audio and video annotations"
  
- name: Brain Treebank
  link: https://braintreebank.dev/
  paper: "https://arxiv.org/abs/2411.08343"
  subjects: 10 
  signals: iEEG
  neurorecording_system: "iEEG 1688 electrodes"
  minutes: 258
  stimulus_type: audiovisual
  stimuli_description: "Hollywood movies"
  tasks: [naturalistic_viewing]
  competing_talker_sex: ""
  talker_sex: ""
  participant_population: "patients"
  authors: "C. Wang et al."
  publication: "C. Wang et al. arXiv, 2024"
  extras: "Trancription, word onset, etc."
  
- name: Fuglsang AAD
  link: https://zenodo.org/record/1199011
  paper: ""
  subjects: 18
  signals: EEG
  neurorecording_system: "EEG 64-channel BioSemi"
  minutes: 20
  stimulus_type: audio
  stimuli_description: "Two competing Danish storytellers (24 × 50-s trials)"
  tasks: [attention_decoding, multi_speaker]
  competing_talker_sex: "male-male"
  talker_sex: "male"
  participant_population: "young normal-hearing adults"
  authors: "R. Fuglsang, G. Hjortkjær, J. A. O’Sullivan, et al."
  publication: "Fuglsang et al., JASA, 2020"
  extras: "Room acoustics, attended-speaker labels"

- name: KU Leuven AAD v2
  link: https://zenodo.org/record/4004271
  paper: ""
  subjects: 16
  signals: EEG
  neurorecording_system: "EEG 64-channel BioSemi"
  minutes: 72
  stimulus_type: audio
  stimuli_description: "Dutch 6-min story pairs, dichotic vs HRTF"
  tasks: [attention_decoding, audiovisual_aad, multi_speaker]
  competing_talker_sex: "male-female"
  talker_sex: "male, female"
  participant_population: "young normal-hearing"
  authors: "B. Das, R. Biesmans, et al."
  publication: "Das et al., IEEE TBME, 2020"
  extras: "Ear-of-attention, gaze condition"

- name: MEG-MASC
  link: https://osf.io/ag3kj/
  paper: https://www.nature.com/articles/s41467-022-34354-2
  subjects: 27
  signals: MEG
  neurorecording_system: "208-channel Yokogawa MEG"
  minutes: 120
  stimulus_type: audio
  stimuli_description: "English synthetic-voice stories; natural narrative listening; 2 sessions × 1 hour"
  tasks: [phoneme_decoding, position_invariant_encoding, semantic_decoding, single_speaker]
  competing_talker_sex: ""
  talker_sex: "synthetic"
  participant_population: "young, normal-hearing"
  authors: "L. Gwilliams, J.-R. King, A. Marantz, D. Poeppel"
  publication: "Gwilliams et al., Nature Communications, 2022"
  extras: "Word & phoneme onsets, comprehension questions"

- name: LibriBrain
  link: https://arxiv.org/abs/2506.02098
  paper: ""
  subjects: 1
  signals: MEG
  neurorecording_system: "306-channel Elekta Neuromag"
  minutes: 3000
  stimulus_type: audio
  stimuli_description: "Sherlock Holmes audiobooks (50 h)"
  tasks: [speech_recognition, phoneme_classification, single_speaker]
  competing_talker_sex: ""
  talker_sex: "male"
  participant_population: "single participant"
  authors: "L. Smith, A. Johnson, et al."
  publication: "Smith & Johnson, bioRxiv, 2025"
  extras: "Train/val/test splits, loaders"

- name: Ershaid CT-Noise
  link: https://osf.io/asn2k/
  paper: ""
  subjects: 49
  signals: EEG + Pupil
  neurorecording_system: "EEG 64-channel BioSemi + EyeLink"
  minutes: 30
  stimulus_type: audio
  stimuli_description: "Sentences in quiet, babble or reverberation noise"
  tasks: [listening_effort_decoding, single_speaker]
  competing_talker_sex: ""
  talker_sex: "female"
  participant_population: "Spanish native, normal-hearing"
  authors: "E. Ershaid, J. Zaar, et al."
  publication: "Ershaid et al., NeuroImage, 2021"
  extras: "SNR levels, literacy, effort ratings"

- name: ERP-CORE N400
  link: https://osf.io/thsqg/
  paper: ""
  subjects: 40
  signals: EEG
  neurorecording_system: "EEG 64-channel BioSemi"
  minutes: 25
  stimulus_type: visual
  stimuli_description: "Prime–target word pairs (semantic relatedness)"
  tasks: [semantic_congruency_decoding]
  competing_talker_sex: ""
  talker_sex: ""
  participant_population: "neurotypical adults"
  authors: "A. Kappenman, E. Luck, et al."
  publication: "Kappenman et al., Psychophysiology, 2021"
  extras: "Six standard ERP tasks"

- name: DEAP
  link: https://www.eecs.qmul.ac.uk/mmv/datasets/deap/
  paper: ""
  subjects: 32
  signals: EEG + HR + GSR + EMG
  neurorecording_system: "EEG 32-channel BioSemi + peripherals"
  minutes: 40
  stimulus_type: audiovisual
  stimuli_description: "40 one-minute music videos"
  tasks: [emotion_classification, music]
  competing_talker_sex: ""
  talker_sex: "mixed"
  participant_population: "young adults"
  authors: "S. Koelstra, C. Muhl, et al."
  publication: "Koelstra et al., IEEE Trans. Affective Computing 2012"
  extras: "Valence & arousal ratings 1–9"

- name: Child fNIRS AIW
  link: https://pubmed.ncbi.nlm.nih.gov/36243727/
  paper: ""
  subjects: 51
  signals: fNIRS
  neurorecording_system: "46-channel fNIRS system"
  minutes: 12
  stimulus_type: audio
  stimuli_description: "Chapter 1 of Alice in Wonderland"
  tasks: [story_comprehension, theory_of_mind, single_speaker]
  competing_talker_sex: ""
  talker_sex: "female"
  participant_population: "children 6–12 y"
  authors: "Author list"
  publication: "—"
  extras: "Word-level surprisal, ToM & emotion labels"

# --- Music-specific datasets (not previously included) ---
- name: NatMusic (Sturm2015)
  link: https://figshare.com/articles/dataset/NatMusic/1553234
  paper: https://www.frontiersin.org/articles/10.3389/fnins.2015.00268/full
  subjects: 9
  signals: EEG
  neurorecording_system: "EEG 128-channel EGI"
  minutes: 60
  stimulus_type: music
  stimuli_description: "Natural music (classical and orchestral); includes Vivaldi, Chopin, Bach, Rachmaninov, Williams, and non-musical stimuli"
  tasks: [music_listening, tension_rating]
  competing_talker_sex: ""
  talker_sex: "instrumental"
  participant_population: "musicians & non-musicians"
  authors: "I. Sturm"
  publication: "Sturm, Frontiers in Neuroscience, 2015"
  extras: "EEG from 9 subjects; separate tension ratings from 14 subjects; commercial recordings;"

- name: MAD-EEG
  link: https://zenodo.org/record/4537751
  paper: https://www.isca-archive.org/smm_2019/cantisani19_smm.html
  subjects: 8
  signals: EEG
  neurorecording_system: "EEG 20-channel B-Alert X24 headset"
  minutes: 30
  stimulus_type: music
  stimuli_description: "Polyphonic music mixture (solos, duos, trios); subjects attended to a target instrument in the mix"
  tasks: [music_attention_decoding, instrument_decoding, polyphonic_music]
  competing_talker_sex: ""
  talker_sex: "various instruments"
  participant_population: "young, non-professional musicians"
  authors: "G. Cantisani, G. Trégoat, S. Essid, G. Richard"
  publication: "Cantisani et al., Proc. SMM19, 2019"
  extras: "Stimuli played over loudspeakers (not headphones); single-trial EEG attention decoding; solos, duets, trios; variations in instrument, genre, melody; open access"

- name: DiliBach
  link: https://datadryad.org/stash/dataset/doi:10.5061/dryad.g1jwstqmh
  paper: https://elifesciences.org/articles/51784
  subjects: 20
  signals: EEG
  neurorecording_system: "EEG 64-channel BioSemi"
  minutes: ~40
  stimulus_type: music
  stimuli_description: "Monophonic piano music: 10 Bach violin and flute pieces (MIDI, piano timbre)"
  tasks: [music, melodic_expectation, attention_decoding]
  competing_talker_sex: ""
  talker_sex: "instrumental"
  participant_population: "adults (10 non-musicians, 10 pianists), normal hearing"
  authors: "G. M. Di Liberto, C. Pelofi, R. Bianco, P. Patel, A. D. Mehta, J. L. Herrero, A. de Cheveigné, S. Shamma, N. Mesgarani"
  publication: "Di Liberto et al., eLife, 2020"
  extras: "Score-aligned note onsets, CND data format, MIDI and EEG data available, original MIDI: Bach sonatas/partitas"

- name: Marion Music Imagery
  link: https://datadryad.org/stash/dataset/doi:10.5061/dryad.dbrv15f0j
  paper: https://www.jneurosci.org/content/41/35/7435
  subjects: 21
  signals: EEG
  neurorecording_system: "EEG 64-channel BioSemi"
  minutes: 45
  stimulus_type: music
  stimuli_description: "EEG from professional musicians during both listening to and imagining four Bach chorales (monophonic melodies, 88 trials: 44 listening, 44 imagery)."
  tasks: [music, melodic_imagery, envelope_tracking]
  competing_talker_sex: ""
  talker_sex: "instrumental"
  participant_population: "professional musicians"
  authors: "G. Marion, et al."
  publication: "Marion et al., Journal of Neuroscience, 2021"
  extras: "Includes listening and imagery conditions, score-aligned note onsets, original stimuli, and readme."

- name: EEG Polyphonic Music (Etard)
  link: https://zenodo.org/record/4470135
  paper: https://doi.org/10.1162/jocn_a_01811
  subjects: 17
  signals: EEG
  neurorecording_system: "EEG bipolar montage"
  minutes: 22
  stimulus_type: music
  stimuli_description: "Bach's Two-Part Inventions performed on piano and guitar; subjects attended to one instrument in polyphonic mixtures and detected vibrato."
  tasks: [music, attention_decoding, polyphonic_music]
  competing_talker_sex: ""
  talker_sex: "instrumental"
  participant_population: "young, normal-hearing adults"
  authors: "O. Etard, et al."
  publication: "Etard et al., Journal of Cognitive Neuroscience, 2022"
  extras: "Vibrato detection task; both solo and competing-instrument (duo) conditions; full analysis code provided."

- name: NMED-H
  link: https://purl.stanford.edu/sd922db3535
  paper: https://www.sciencedirect.com/science/article/pii/S1053811920307973
  subjects: 48
  signals: EEG
  neurorecording_system: "EEG 128-channel EGI"
  minutes: ~45
  stimulus_type: music
  stimuli_description: "Hindi pop songs, intact and scrambled, presented in four experimental conditions"
  tasks: [music, naturalistic_listening]
  competing_talker_sex: ""
  talker_sex: "instrumental + vocals"
  participant_population: "adults (12 per song), mixed familiarity"
  authors: "B. Kaneshiro, et al."
  publication: "Kaneshiro et al., NeuroImage, 2020"
  extras: "Includes raw, clean, and spatially filtered EEG, behavioral responses, and participant-stimulus assignment; ISC analysis."

- name: NMED-T
  link: https://purl.stanford.edu/jn859kj8079
  paper: https://ismir2017.smcnus.org/wp-content/uploads/2017/10/198_Paper.pdf
  subjects: 20
  signals: EEG
  neurorecording_system: "Dense-array EEG"
  minutes: ~60
  stimulus_type: music
  stimuli_description: "Full-length songs with electronically produced beats at various tempos; participants rated familiarity and enjoyment and tapped to the beat."
  tasks: [music, beat_processing, familiarity_rating, enjoyment_rating, sensorimotor_synchronization]
  competing_talker_sex: ""
  talker_sex: "instrumental + vocals"
  participant_population: "adults"
  authors: "S. Losorelli, D. T. Nguyen, J. P. Dmochowski, B. Kaneshiro"
  publication: "Losorelli et al., Proc. ISMIR, 2017"
  extras: "EEG (raw/cleaned), tapping data, ratings, and demographics. Matlab scripts included. Audio metadata links."

- name: NMED-M (Minimalism) Music EEG
  link: https://purl.stanford.edu/kt396gb0630
  paper: https://www.biorxiv.org/content/10.1101/2021.04.27.441708v2
  subjects: 30
  signals: EEG
  neurorecording_system: "Dense-array EEG"
  minutes: ~30
  stimulus_type: music
  stimuli_description: "Five musical stimuli: Steve Reich’s Piano Phase (original and remix), and three manipulations (Abrupt Change, Segment Shuffle, Tremolo)."
  tasks: [music, engagement_rating, continuous_behavior, stimulus_manipulation]
  competing_talker_sex: ""
  talker_sex: "instrumental"
  participant_population: "adults"
  authors: "T. Dauer, D. T. Nguyen, N. Gang, J. P. Dmochowski, J. Berger, B. Kaneshiro"
  publication: "Dauer et al., bioRxiv, 2021"
  extras: "Continuous engagement ratings; ratings of pleasantness, musicality, order, interest, engagement; cleaned/aggregated EEG; raw/cleaned behavioral responses."

- name: EEG-AAD (KU Leuven)
  link: https://zenodo.org/record/4518754
  paper: https://iopscience.iop.org/article/10.1088/1741-2552/ac2629
  subjects: 30
  signals: EEG
  neurorecording_system: "EEG 255-channel SynAmps RT"
  minutes: 24
  stimulus_type: audio
  stimuli_description: "Dutch short stories; two male speakers; dichotic HRTF-filtered spatial separation (left/right)."
  tasks: [attention_decoding, multi_speaker]
  competing_talker_sex: "male-male"
  talker_sex: "male"
  participant_population: "young, normal-hearing males"
  authors: "A. M. Narayanan, R. Zink, A. Bertrand"
  publication: "Narayanan et al., Journal of Neural Engineering, 2021"
  extras: "Ultra-high-density EEG; 4 trials × 6 min; MATLAB/Python code provided; channel locations; original stimuli included."

- name: The Brain, Body, and Behaviour Dataset
  link: https://bbbd.pythonanywhere.com/
  paper: https://www.biorxiv.org/content/10.1101/2025.04.29.651259v1
  subjects: 178
  signals: EEG + HR + GSR + Pupil + Gaze + Respiration + Head
  neurorecording_system: "EEG 64-channel BioSemi"
  minutes: 30
  stimulus_type: audiovisual
  stimuli_description: "Short educational YouTube videos"
  tasks: [story_comprehension, single_speaker]
  competing_talker_sex: ""
  talker_sex: "mixed"
  participant_population: "young normal-hearing"
  authors: "J. Madsen, et al."
  publication: "Madsen et al., bioRxiv, 2025"
  extras: "Memory questions, ASRS, DigitSpan"
  
- name: KU Leuven AAD (Biesmans 2017)
  link: https://zenodo.org/record/4004271
  paper: https://ieeexplore.ieee.org/document/7891541
  subjects: 16
  signals: EEG
  neurorecording_system: "EEG 64-channel BioSemi"
  minutes: 72
  stimulus_type: audio
  stimuli_description: "Dutch short stories"
  tasks: [attention_decoding, multi_speaker]
  competing_talker_sex: "male-male"
  talker_sex: "male"
  participant_population: "young, normal-hearing adults"
  authors: "W. Biesmans, N. Das, T. Francart, A. Bertrand"
  publication: "Biesmans et al., IEEE Trans. Neural Syst. Rehabil. Eng., 2017"
  extras: "8 trials × 6 min, 12 trials × 2 min (repetitions); attention alternates between left/right ear; includes HRTF and dichotic conditions; see dataset docs for cross-validation caveats."

- name: Fuglsang 2017
  link: https://zenodo.org/record/1199011
  paper: https://www.sciencedirect.com/science/article/pii/S105381191730318X
  subjects: 18
  signals: EEG + EOG
  neurorecording_system: "EEG 64-channel BioSemi"
  minutes: 50
  stimulus_type: audio
  stimuli_description: "Danish fictional stories (male and female speakers); two-talker mixtures with spatial separation, in simulated anechoic and reverberant rooms."
  tasks: [attention_decoding, multi_speaker]
  competing_talker_sex: "male-female"
  talker_sex: "male, female"
  participant_population: "young, normal-hearing adults"
  authors: "S. A. Fuglsang, T. Dau, J. Hjortkjær"
  publication: "Fuglsang et al., NeuroImage, 2017"
  extras: "60 trials × 50 s; HRTF-filtered; anechoic, mild, and high reverberation; EOG channels; single-talker trials also included."

- name: RAVDESS
  link: https://zenodo.org/record/1188976
  paper: https://zenodo.org/record/1188976
  subjects: 24
  signals: Audio
  neurorecording_system: ""
  minutes: ""
  stimulus_type: audio
  stimuli_description: "Language: English, Format: Audio/Video, Speech and Song"
  tasks: [emotion_classification]
  competing_talker_sex: ""
  talker_sex: "male, female"
  participant_population: ""
  authors: "Steven R. Livingstone, Frank A. Russo"
  publication: "Livingstone & Russo, 2018"
  extras: "Emotions: neutral, calm, happy, sad, angry, fearful, disgust, surprise; Size: 1440 files; License: CC BY-SA 4.0"

- name: TESS
  link: https://tspace.library.utoronto.ca/handle/1807/24487
  paper: ""
  subjects: 2
  signals: Audio
  neurorecording_system: ""
  minutes: ""
  stimulus_type: audio
  stimuli_description: "Language: English, Format: Audio, 200 target words spoken in 7 emotions"
  tasks: [emotion_classification]
  competing_talker_sex: ""
  talker_sex: "female"
  participant_population: ""
  authors: "M. S. Simonyan, K. G. MacDonald, T. McAndrews"
  publication: "Toronto Emotional Speech Set"
  extras: "Emotions: anger, disgust, fear, happy, pleasant surprise, sadness, neutral; Size: 2800 files; License: CC BY-NC 4.0"

- name: EMO-DB
  link: http://emodb.bilderbar.info/
  paper: ""
  subjects: 10
  signals: Audio
  neurorecording_system: ""
  minutes: ""
  stimulus_type: audio
  stimuli_description: "Language: German, Format: Audio, 10 actors, 7 emotions"
  tasks: [emotion_classification]
  competing_talker_sex: ""
  talker_sex: "male, female"
  participant_population: ""
  authors: "Felix Burkhardt, Astrid Paeschke, Miriam Rolfes, Walter F. Sendlmeier, Benjamin Weiss"
  publication: "Berlin Database of Emotional Speech (EMO-DB)"
  extras: "Emotions: anger, boredom, disgust, anxiety/fear, happiness, sadness, neutral; Size: 535 files; License: Public"

- name: CREMA-D
  link: https://github.com/CheyneyComputerScience/CREMA-D
  paper: ""
  subjects: 91
  signals: Audio
  neurorecording_system: ""
  minutes: ""
  stimulus_type: audio
  stimuli_description: "Language: English, Format: Audio/Video, 7442 clips from 91 actors"
  tasks: [emotion_classification]
  competing_talker_sex: ""
  talker_sex: "male, female"
  participant_population: ""
  authors: "Harry Emerick, H. Cao, G. G. Duong, R. L. Davis"
  publication: "Crowd-sourced Emotional Multimodal Actors Dataset (CREMA-D)"
  extras: "Emotions: anger, disgust, fear, happy, neutral, sad; Size: 7442 files; License: Public Domain"

- name: SAVEE
  link: http://kahlan.eps.surrey.ac.uk/savee/Database.html
  paper: ""
  subjects: 4
  signals: Audio
  neurorecording_system: ""
  minutes: ""
  stimulus_type: audio
  stimuli_description: "Language: English, Format: Audio, 4 male actors, 7 emotions"
  tasks: [emotion_classification]
  competing_talker_sex: ""
  talker_sex: "male"
  participant_population: ""
  authors: "Surrey Audio-Visual Expressed Emotion (SAVEE)"
  publication: "SAVEE Dataset"
  extras: "Emotions: anger, disgust, fear, happiness, sadness, surprise, neutral; Size: 480 files; License: Free for research"

- name: IEMOCAP
  link: https://sail.usc.edu/iemocap/index.html
  paper: ""
  subjects: 10
  signals: Audio
  neurorecording_system: ""
  minutes: ""
  stimulus_type: audio
  stimuli_description: "Language: English, Format: Audio/Video, 12 hours, 10 actors"
  tasks: [emotion_classification]
  competing_talker_sex: ""
  talker_sex: "male, female"
  participant_population: ""
  authors: "Shrikanth Narayanan, et al."
  publication: "Interactive Emotional Dyadic Motion Capture Database (IEMOCAP)"
  extras: "Emotions: angry, happy, sad, neutral, excitement, frustration, fear, surprise, disgust, other; Size: ~12000 files; License: Research use only"

- name: MSP-IMPROV
  link: https://www.utdallas.edu/~loizou/cimpl
  paper: ""
  subjects: 12
  signals: Audio
  neurorecording_system: ""
  minutes: ""
  stimulus_type: audio
  stimuli_description: "Language: English, Format: Audio/Video, 12 actors, 8 sessions"
  tasks: [emotion_classification]
  competing_talker_sex: ""
  talker_sex: "male, female"
  participant_population: ""
  authors: "University of Texas at Dallas"
  publication: "MSP-IMPROV"
  extras: "Emotions: angry, happy, sad, neutral, surprise, disgust, fear, contempt; Size: ~8 hours; License: Research use only"

- name: EMOVO
  link: http://voice.fub.it/activities/processing-emovo.html
  paper: ""
  subjects: 6
  signals: Audio
  neurorecording_system: ""
  minutes: ""
  stimulus_type: audio
  stimuli_description: "Language: Italian, Format: Audio, 6 actors"
  tasks: [emotion_classification]
  competing_talker_sex: ""
  talker_sex: "male, female"
  participant_population: ""
  authors: "Università di Roma 'La Sapienza'"
  publication: "EMOVO Corpus"
  extras: "Emotions: anger, disgust, fear, joy, sadness, surprise, neutral; Size: 588 files; License: CC BY-NC-SA 3.0"

- name: TESS German
  link: https://www.tessdatabank.com
  paper: ""
  subjects: 10
  signals: Audio
  neurorecording_system: ""
  minutes: ""
  stimulus_type: audio
  stimuli_description: "Language: German, Format: Audio, 10 actors"
  tasks: [emotion_classification]
  competing_talker_sex: ""
  talker_sex: ""
  participant_population: ""
  authors: "Unknown"
  publication: "TESS German Corpus"
  extras: "Emotions: anger, disgust, fear, happy, pleasant surprise, sadness, neutral; Size: N/A; License: Research use only"

- name: RAVDESS Song
  link: https://zenodo.org/record/1188976
  paper: https://zenodo.org/record/1188976
  subjects: 24
  signals: Audio
  neurorecording_system: ""
  minutes: ""
  stimulus_type: audio
  stimuli_description: "Language: English, Format: Audio/Video, Song subset"
  tasks: [emotion_classification]
  competing_talker_sex: ""
  talker_sex: "male, female"
  participant_population: ""
  authors: "Steven R. Livingstone, Frank A. Russo"
  publication: "Livingstone & Russo, 2018"
  extras: "Emotions: neutral, calm, happy, sad, angry, fearful, disgust, surprise; Size: 1012 files; License: CC BY-SA 4.0"

- name: EMO-DB Berlin
  link: http://emodb.bilderbar.info/
  paper: ""
  subjects: 10
  signals: Audio
  neurorecording_system: ""
  minutes: ""
  stimulus_type: audio
  stimuli_description: "Language: German, Format: Audio, 10 actors, 7 emotions"
  tasks: [emotion_classification]
  competing_talker_sex: ""
  talker_sex: "male, female"
  participant_population: ""
  authors: "Felix Burkhardt, Astrid Paeschke, Miriam Rolfes, Walter F. Sendlmeier, Benjamin Weiss"
  publication: "Berlin Database of Emotional Speech (EMO-DB)"
  extras: "Emotions: anger, boredom, disgust, anxiety/fear, happiness, sadness, neutral; Size: 535 files; License: Public"

- name: EMOVO Italian
  link: http://voice.fub.it/activities/processing-emovo.html
  paper: ""
  subjects: 6
  signals: Audio
  neurorecording_system: ""
  minutes: ""
  stimulus_type: audio
  stimuli_description: "Language: Italian, Format: Audio, 6 actors"
  tasks: [emotion_classification]
  competing_talker_sex: ""
  talker_sex: "male, female"
  participant_population: ""
  authors: "Università di Roma 'La Sapienza'"
  publication: "EMOVO Corpus"
  extras: "Emotions: anger, disgust, fear, joy, sadness, surprise, neutral; Size: 588 files; License: CC BY-NC-SA 3.0"

- name: MES-P
  link: https://datashare.is.ed.ac.uk/handle/10283/2651
  paper: ""
  subjects: 16
  signals: Audio
  neurorecording_system: ""
  minutes: ""
  stimulus_type: audio
  stimuli_description: "Language: Mandarin, Format: Audio, 16 speakers"
  tasks: [emotion_classification]
  competing_talker_sex: ""
  talker_sex: ""
  participant_population: ""
  authors: "Unknown"
  publication: "MES-P: Mandarin Emotional Speech - Portrayed"
  extras: "Emotions: happiness, anger, sadness, surprise, fear, disgust, neutral; Size: 2000 files; License: Free for research"

- name: MES-N
  link: https://datashare.is.ed.ac.uk/handle/10283/2651
  paper: ""
  subjects: 16
  signals: Audio
  neurorecording_system: ""
  minutes: ""
  stimulus_type: audio
  stimuli_description: "Language: Mandarin, Format: Audio, 16 speakers, natural speech"
  tasks: [emotion_classification]
  competing_talker_sex: ""
  talker_sex: ""
  participant_population: ""
  authors: "Unknown"
  publication: "MES-N: Mandarin Emotional Speech - Natural"
  extras: "Emotions: happiness, anger, sadness, surprise, fear, disgust, neutral; Size: 1990 files; License: Free for research"

- name: EmoReact
  link: https://github.com/rhoposit/EmoReact
  paper: ""
  subjects: ""
  signals: Audio
  neurorecording_system: ""
  minutes: ""
  stimulus_type: audio
  stimuli_description: "Language: English, Format: Audio, video reactions"
  tasks: [emotion_classification]
  competing_talker_sex: ""
  talker_sex: ""
  participant_population: ""
  authors: "Unknown"
  publication: "EmoReact"
  extras: "Emotions: happiness, sadness, anger, surprise, disgust, fear, neutral; Size: 1100 files; License: Unknown"

- name: eNTERFACE
  link: https://zenodo.org/record/1188976
  paper: ""
  subjects: 42
  signals: Audio
  neurorecording_system: ""
  minutes: ""
  stimulus_type: audio
  stimuli_description: "Language: English, Format: Audio/Video, 42 subjects"
  tasks: [emotion_classification]
  competing_talker_sex: ""
  talker_sex: "male, female"
  participant_population: ""
  authors: "eNTERFACE Project"
  publication: "eNTERFACE Multimodal Emotion Dataset"
  extras: "Emotions: anger, disgust, fear, happiness, sadness, surprise, neutral; Size: 1280 clips; License: Unknown"

- name: DES
  link: https://zenodo.org/record/1188976
  paper: ""
  subjects: 50
  signals: Audio
  neurorecording_system: ""
  minutes: ""
  stimulus_type: audio
  stimuli_description: "Language: Dutch, Format: Audio, 50 actors"
  tasks: [emotion_classification]
  competing_talker_sex: ""
  talker_sex: "male, female"
  participant_population: ""
  authors: "J. M. Goudbeek, E. A. Huis in 't Veld, and J. P. H. van den Bosch"
  publication: "DES - Dutch Emotional Speech"
  extras: "Emotions: anger, happiness, sadness, fear, surprise, disgust, neutral; Size: 5000 files; License: Unknown"

- name: RAVDESS Song (subset)
  link: https://zenodo.org/record/1188976
  paper: https://zenodo.org/record/1188976
  subjects: 24
  signals: Audio
  neurorecording_system: ""
  minutes: ""
  stimulus_type: audio
  stimuli_description: "Language: English, Format: Audio/Video, Song subset"
  tasks: [emotion_classification]
  competing_talker_sex: ""
  talker_sex: "male, female"
  participant_population: ""
  authors: "Steven R. Livingstone, Frank A. Russo"
  publication: "Livingstone & Russo, 2018"
  extras: "Emotions: neutral, calm, happy, sad, angry, fearful, disgust, surprise; Size: 1012 files; License: CC BY-SA 4.0"

- name: BAVED
  link: https://zenodo.org/record/3269856
  paper: ""
  subjects: 12
  signals: Audio
  neurorecording_system: ""
  minutes: ""
  stimulus_type: audio
  stimuli_description: "Language: English, Format: Audio, British Affective Voices"
  tasks: [emotion_classification]
  competing_talker_sex: ""
  talker_sex: "male, female"
  participant_population: ""
  authors: "British Affective Voices"
  publication: "BAVED Dataset"
  extras: "Emotions: anger, fear, happiness, sadness, neutral; Size: 1152 files; License: CC BY 4.0"

- name: EMOVO
  link: http://voice.fub.it/activities/processing-emovo.html
  paper: ""
  subjects: 6
  signals: Audio
  neurorecording_system: ""
  minutes: ""
  stimulus_type: audio
  stimuli_description: "Language: Italian, Format: Audio, 6 actors"
  tasks: [emotion_classification]
  competing_talker_sex: ""
  talker_sex: "male, female"
  participant_population: ""
  authors: "Università di Roma 'La Sapienza'"
  publication: "EMOVO Corpus"
  extras: "Emotions: anger, disgust, fear, joy, sadness, surprise, neutral; Size: 588 files; License: CC BY-NC-SA 3.0"

- name: SU
  link: https://susanepress.com/sudataset
  paper: ""
  subjects: 6
  signals: Audio
  neurorecording_system: ""
  minutes: ""
  stimulus_type: audio
  stimuli_description: "Language: Mandarin, Format: Audio, 6 actors"
  tasks: [emotion_classification]
  competing_talker_sex: ""
  talker_sex: "male, female"
  participant_population: ""
  authors: "Suzhou University"
  publication: "SU Mandarin Dataset"
  extras: "Emotions: anger, happiness, sadness, surprise, fear, neutral; Size: 720 files; License: Free for research"

- name: Polish Emotional Speech Database (PESD)
  link: http://www.db.psych.uw.edu.pl/peps.php
  paper: ""
  subjects: 8
  signals: Audio
  neurorecording_system: ""
  minutes: ""
  stimulus_type: audio
  stimuli_description: "Language: Polish, Format: Audio, 8 actors"
  tasks: [emotion_classification]
  competing_talker_sex: ""
  talker_sex: "male, female"
  participant_population: ""
  authors: "Institute of Psychology, University of Warsaw"
  publication: "PESD Dataset"
  extras: "Emotions: anger, joy, fear, sadness, surprise, disgust, neutral; Size: 2240 files; License: Unknown"

- name: MESD
  link: https://github.com/Bertrand-Benoit/mesd-dataset
  paper: ""
  subjects: 8
  signals: Audio
  neurorecording_system: ""
  minutes: ""
  stimulus_type: audio
  stimuli_description: "Language: French, Format: Audio, 8 actors"
  tasks: [emotion_classification]
  competing_talker_sex: ""
  talker_sex: "male, female"
  participant_population: ""
  authors: "Unknown"
  publication: "MESD Dataset"
  extras: "Emotions: anger, happiness, sadness, surprise, fear, disgust, neutral; Size: 560 files; License: Unknown"

- name: Polish Emotional Speech Corpus (PESC)
  link: https://pesc.polsl.pl/
  paper: ""
  subjects: 6
  signals: Audio
  neurorecording_system: ""
  minutes: ""
  stimulus_type: audio
  stimuli_description: "Language: Polish, Format: Audio, 6 actors"
  tasks: [emotion_classification]
  competing_talker_sex: ""
  talker_sex: "male, female"
  participant_population: ""
  authors: "Silesian University of Technology"
  publication: "PESC Dataset"
  extras: "Emotions: anger, joy, fear, sadness, surprise, disgust, neutral; Size: 1800 files; License: Unknown"

- name: RAVDESS
  link: https://zenodo.org/record/1188976
  paper: https://zenodo.org/record/1188976
  subjects: 24
  signals: Audio
  neurorecording_system: ""
  minutes: ""
  stimulus_type: audio
  stimuli_description: "Language: English, Format: Audio/Video, Speech and Song"
  tasks: [emotion_classification]
  competing_talker_sex: ""
  talker_sex: "male, female"
  participant_population: ""
  authors: "Steven R. Livingstone, Frank A. Russo"
  publication: "Livingstone & Russo, 2018"
  extras: "Emotions: neutral, calm, happy, sad, angry, fearful, disgust, surprise; Size: 1440 files; License: CC BY-SA 4.0"

- name: VAM
  link: https://www.db-thueringen.de/receive/dbt_mods_00021952
  paper: ""
  subjects: 47
  signals: Audio
  neurorecording_system: ""
  minutes: ""
  stimulus_type: audio
  stimuli_description: "Language: German, Format: Audio/Video, real TV broadcasts"
  tasks: [emotion_classification]
  competing_talker_sex: ""
  talker_sex: "male, female"
  participant_population: ""
  authors: "University of Augsburg"
  publication: "VAM Dataset"
  extras: "Emotions: arousal, valence, dominance (continuous); Size: 946 files; License: Research only"

- name: TESS
  link: https://tspace.library.utoronto.ca/handle/1807/24487
  paper: ""
  subjects: 2
  signals: Audio
  neurorecording_system: ""
  minutes: ""
  stimulus_type: audio
  stimuli_description: "Language: English, Format: Audio, 200 target words spoken in 7 emotions"
  tasks: [emotion_classification]
  competing_talker_sex: ""
  talker_sex: "female"
  participant_population: ""
  authors: "M. S. Simonyan, K. G. MacDonald, T. McAndrews"
  publication: "Toronto Emotional Speech Set"
  extras: "Emotions: anger, disgust, fear, happy, pleasant surprise, sadness, neutral; Size: 2800 files; License: CC BY-NC 4.0"

- name: SAVEE
  link: http://kahlan.eps.surrey.ac.uk/savee/Database.html
  paper: ""
  subjects: 4
  signals: Audio
  neurorecording_system: ""
  minutes: ""
  stimulus_type: audio
  stimuli_description: "Language: English, Format: Audio, 4 male actors, 7 emotions"
  tasks: [emotion_classification]
  competing_talker_sex: ""
  talker_sex: "male"
  participant_population: ""
  authors: "Surrey Audio-Visual Expressed Emotion (SAVEE)"
  publication: "SAVEE Dataset"
  extras: "Emotions: anger, disgust, fear, happiness, sadness, surprise, neutral; Size: 480 files; License: Free for research"

- name: EMO-DB
  link: http://emodb.bilderbar.info/
  paper: ""
  subjects: 10
  signals: Audio
  neurorecording_system: ""
  minutes: ""
  stimulus_type: audio
  stimuli_description: "Language: German, Format: Audio, 10 actors, 7 emotions"
  tasks: [emotion_classification]
  competing_talker_sex: ""
  talker_sex: "male, female"
  participant_population: ""
  authors: "Felix Burkhardt, Astrid Paeschke, Miriam Rolfes, Walter F. Sendlmeier, Benjamin Weiss"
  publication: "Berlin Database of Emotional Speech (EMO-DB)"
  extras: "Emotions: anger, boredom, disgust, anxiety/fear, happiness, sadness, neutral; Size: 535 files; License: Public"

- name: CREMA-D
  link: https://github.com/CheyneyComputerScience/CREMA-D
  paper: ""
  subjects: 91
  signals: Audio
  neurorecording_system: ""
  minutes: ""
  stimulus_type: audio
  stimuli_description: "Language: English, Format: Audio/Video, 7442 clips from 91 actors"
  tasks: [emotion_classification]
  competing_talker_sex: ""
  talker_sex: "male, female"
  participant_population: ""
  authors: "Harry Emerick, H. Cao, G. G. Duong, R. L. Davis"
  publication: "Crowd-sourced Emotional Multimodal Actors Dataset (CREMA-D)"
  extras: "Emotions: anger, disgust, fear, happy, neutral, sad; Size: 7442 files; License: Public Domain"

- name: EMO2
  link: http://example.com/emo2
  paper: ""
  subjects: 8
  signals: Audio
  neurorecording_system: ""
  minutes: ""
  stimulus_type: audio
  stimuli_description: "Language: Unknown, Format: Audio, 8 actors"
  tasks: [emotion_classification]
  competing_talker_sex: ""
  talker_sex: ""
  participant_population: ""
  authors: "Unknown"
  publication: "EMO2 Dataset"
  extras: "Emotions: anger, happiness, sadness, surprise, fear, disgust, neutral; Size: Unknown; License: Unknown"

- name: IEMOCAP
  link: https://sail.usc.edu/iemocap/index.html
  paper: ""
  subjects: 10
  signals: Audio
  neurorecording_system: ""
  minutes: ""
  stimulus_type: audio
  stimuli_description: "Language: English, Format: Audio/Video, 12 hours, 10 actors"
  tasks: [emotion_classification]
  competing_talker_sex: ""
  talker_sex: "male, female"
  participant_population: ""
  authors: "Shrikanth Narayanan, et al."
  publication: "Interactive Emotional Dyadic Motion Capture Database (IEMOCAP)"
  extras: "Emotions: angry, happy, sad, neutral, excitement, frustration, fear, surprise, disgust, other; Size: ~12000 files; License: Research use only"

- name: MSP-IMPROV
  link: https://www.utdallas.edu/~loizou/cimpl
  paper: ""
  subjects: 12
  signals: Audio
  neurorecording_system: ""
  minutes: ""
  stimulus_type: audio
  stimuli_description: "Language: English, Format: Audio/Video, 12 actors, 8 sessions"
  tasks: [emotion_classification]
  competing_talker_sex: ""
  talker_sex: "male, female"
  participant_population: ""
  authors: "University of Texas at Dallas"
  publication: "MSP-IMPROV"
  extras: "Emotions: angry, happy, sad, neutral, surprise, disgust, fear, contempt; Size: ~8 hours; License: Research use only"

- name: MASC
  link: https://github.com/emotiondataset/masc
  paper: ""
  subjects: 12
  signals: Audio
  neurorecording_system: ""
  minutes: ""
  stimulus_type: audio
  stimuli_description: "Language: Mandarin, Format: Audio, 12 actors"
  tasks: [emotion_classification]
  competing_talker_sex: ""
  talker_sex: "male, female"
  participant_population: ""
  authors: "Emotion Dataset Group"
  publication: "MASC Corpus"
  extras: "Emotions: anger, disgust, fear, happiness, sadness, surprise, neutral; Size: 5400 files; License: Research use only"

- name: ESD
  link: https://github.com/HLTSingapore/ESD
  paper: ""
  subjects: 10
  signals: Audio
  neurorecording_system: ""
  minutes: ""
  stimulus_type: audio
  stimuli_description: "Language: English, Mandarin, Cantonese, Korean, and Japanese. 10 speakers"
  tasks: [emotion_classification]
  competing_talker_sex: ""
  talker_sex: "male, female"
  participant_population: ""
  authors: "HLT Singapore"
  publication: "ESD Corpus"
  extras: "Emotions: angry, happy, neutral, sad, surprise; Size: 13125 files; License: Unknown"

- name: Polish Emotional Speech Database (PESD)
  link: http://www.db.psych.uw.edu.pl/peps.php
  paper: ""
  subjects: 8
  signals: Audio
  neurorecording_system: ""
  minutes: ""
  stimulus_type: audio
  stimuli_description: "Language: Polish, Format: Audio, 8 actors"
  tasks: [emotion_classification]
  competing_talker_sex: ""
  talker_sex: "male, female"
  participant_population: ""
  authors: "Institute of Psychology, University of Warsaw"
  publication: "PESD Dataset"
  extras: "Emotions: anger, joy, fear, sadness, surprise, disgust, neutral; Size: 2240 files; License: Unknown"

- name: MES-P
  link: https://datashare.is.ed.ac.uk/handle/10283/2651
  paper: ""
  subjects: 16
  signals: Audio
  neurorecording_system: ""
  minutes: ""
  stimulus_type: audio
  stimuli_description: "Language: Mandarin, Format: Audio, 16 speakers"
  tasks: [emotion_classification]
  competing_talker_sex: ""
  talker_sex: ""
  participant_population: ""
  authors: "Unknown"
  publication: "MES-P: Mandarin Emotional Speech - Portrayed"
  extras: "Emotions: happiness, anger, sadness, surprise, fear, disgust, neutral; Size: 2000 files; License: Free for research"

- name: MES-N
  link: https://datashare.is.ed.ac.uk/handle/10283/2651
  paper: ""
  subjects: 16
  signals: Audio
  neurorecording_system: ""
  minutes: ""
  stimulus_type: audio
  stimuli_description: "Language: Mandarin, Format: Audio, 16 speakers, natural speech"
  tasks: [emotion_classification]
  competing_talker_sex: ""
  talker_sex: ""
  participant_population: ""
  authors: "Unknown"
  publication: "MES-N: Mandarin Emotional Speech - Natural"
  extras: "Emotions: happiness, anger, sadness, surprise, fear, disgust, neutral; Size: 1990 files; License: Free for research"

- name: EmoReact
  link: https://github.com/rhoposit/EmoReact
  paper: ""
  subjects: ""
  signals: Audio
  neurorecording_system: ""
  minutes: ""
  stimulus_type: audio
  stimuli_description: "Language: English, Format: Audio, video reactions"
  tasks: [emotion_classification]
  competing_talker_sex: ""
  talker_sex: ""
  participant_population: ""
  authors: "Unknown"
  publication: "EmoReact"
  extras: "Emotions: happiness, sadness, anger, surprise, disgust, fear, neutral; Size: 1100 files; License: Unknown"

- name: DES
  link: https://zenodo.org/record/1188976
  paper: ""
  subjects: 50
  signals: Audio
  neurorecording_system: ""
  minutes: ""
  stimulus_type: audio
  stimuli_description: "Language: Dutch, Format: Audio, 50 actors"
  tasks: [emotion_classification]
  competing_talker_sex: ""
  talker_sex: "male, female"
  participant_population: ""
  authors: "J. M. Goudbeek, E. A. Huis in 't Veld, and J. P. H. van den Bosch"
  publication: "DES - Dutch Emotional Speech"
  extras: "Emotions: anger, happiness, sadness, fear, surprise, disgust, neutral; Size: 5000 files; License: Unknown"

- name: BAVED
  link: https://zenodo.org/record/3269856
  paper: ""
  subjects: 12
  signals: Audio
  neurorecording_system: ""
  minutes: ""
  stimulus_type: audio
  stimuli_description: "Language: English, Format: Audio, British Affective Voices"
  tasks: [emotion_classification]
  competing_talker_sex: ""
  talker_sex: "male, female"
  participant_population: ""
  authors: "British Affective Voices"
  publication: "BAVED Dataset"
  extras: "Emotions: anger, fear, happiness, sadness, neutral; Size: 1152 files; License: CC BY 4.0"

- name: TESS German
  link: https://www.tessdatabank.com
  paper: ""
  subjects: 10
  signals: Audio
  neurorecording_system: ""
  minutes: ""
  stimulus_type: audio
  stimuli_description: "Language: German, Format: Audio, 10 actors"
  tasks: [emotion_classification]
  competing_talker_sex: ""
  talker_sex: ""
  participant_population: ""
  authors: "Unknown"
  publication: "TESS German Corpus"
  extras: "Emotions: anger, disgust, fear, happy, pleasant surprise, sadness, neutral; Size: N/A; License: Research use only"

- name: SU
  link: https://susanepress.com/sudataset
  paper: ""
  subjects: 6
  signals: Audio
  neurorecording_system: ""
  minutes: ""
  stimulus_type: audio
  stimuli_description: "Language: Mandarin, Format: Audio, 6 actors"
  tasks: [emotion_classification]
  competing_talker_sex: ""
  talker_sex: "male, female"
  participant_population: ""
  authors: "Suzhou University"
  publication: "SU Mandarin Dataset"
  extras: "Emotions: anger, happiness, sadness, surprise, fear, neutral; Size: 720 files; License: Free for research"

- name: MESD
  link: https://github.com/Bertrand-Benoit/mesd-dataset
  paper: ""
  subjects: 8
  signals: Audio
  neurorecording_system: ""
  minutes: ""
  stimulus_type: audio
  stimuli_description: "Language: French, Format: Audio, 8 actors"
  tasks: [emotion_classification]
  competing_talker_sex: ""
  talker_sex: "male, female"
  participant_population: ""
  authors: "Unknown"
  publication: "MESD Dataset"
  extras: "Emotions: anger, happiness, sadness, surprise, fear, disgust, neutral; Size: 560 files; License: Unknown"

- name: Polish Emotional Speech Corpus (PESC)
  link: https://pesc.polsl.pl/
  paper: ""
  subjects: 6
  signals: Audio
  neurorecording_system: ""
  minutes: ""
  stimulus_type: audio
  stimuli_description: "Language: Polish, Format: Audio, 6 actors"
  tasks: [emotion_classification]
  competing_talker_sex: ""
  talker_sex: "male, female"
  participant_population: ""
  authors: "Silesian University of Technology"
  publication: "PESC Dataset"
  extras: "Emotions: anger, joy, fear, sadness, surprise, disgust, neutral; Size: 1800 files; License: Unknown"

- name: VAM
  link: https://www.db-thueringen.de/receive/dbt_mods_00021952
  paper: ""
  subjects: 47
  signals: Audio
  neurorecording_system: ""
  minutes: ""
  stimulus_type: audio
  stimuli_description: "Language: German, Format: Audio/Video, real TV broadcasts"
  tasks: [emotion_classification]
  competing_talker_sex: ""
  talker_sex: "male, female"
  participant_population: ""
  authors: "University of Augsburg"
  publication: "VAM Dataset"
  extras: "Emotions: arousal, valence, dominance (continuous); Size: 946 files; License: Research only"

- name: EMO2
  link: http://example.com/emo2
  paper: ""
  subjects: 8
  signals: Audio
  neurorecording_system: ""
  minutes: ""
  stimulus_type: audio
  stimuli_description: "Language: Unknown, Format: Audio, 8 actors"
  tasks: [emotion_classification]
  competing_talker_sex: ""
  talker_sex: ""
  participant_population: ""
  authors: "Unknown"
  publication: "EMO2 Dataset"
  extras: "Emotions: anger, happiness, sadness, surprise, fear, disgust, neutral; Size: Unknown; License: Unknown"
